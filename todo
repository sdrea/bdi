Please rerun simulations based on the second approach: tag array the same- reducing data array by a factor of 
two.  I expect small slow-down relative to the baseline scheme with large power savings.

in cache.c size_compressed += 128 - bdi_size; I am not sure why bdi_size should be subtracted from 128.

in cache.c cp->sim_tag_read_dynamic_energy += cp->assoc*cp->cacti_tag_read_dynamic_energy;

I think Cacti reports energy for all ways within a set. You do not need to multiply energy by cp->assoc.

the same here for cache hit:
  cp->sim_tag_read_dynamic_energy += cp->assoc*cp->cacti_tag_read_dynamic_energy;

for dynamic power of read and write, you need to check cmd (Read or Write) in cache.c. Now, both commands are 
treated equally.

Latency of decompression should be accounted only for read 
  if (cp->bdi_compress) lat += cp->decompression_latency;
decompression_latency should be accounted only for read hit. In the event of miss, uncompressed block is read 
from memory and is brought to L2.
